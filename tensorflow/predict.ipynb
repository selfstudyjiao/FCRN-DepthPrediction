{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Depth Prediction with Fully Convolutional Residual Networks\n",
    "\n",
    "By [Iro Laina](http://campar.in.tum.de/Main/IroLaina), [Christian Rupprecht](http://campar.in.tum.de/Main/ChristianRupprecht), [Vasileios Belagiannis](http://www.robots.ox.ac.uk/~vb/), [Federico Tombari](http://campar.in.tum.de/Main/FedericoTombari), [Nassir Navab](http://campar.in.tum.de/Main/NassirNavab).\n",
    "\n",
    "Modified from predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as im\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n",
      "Model is ready\n",
      "--- Model loading time: 136.79332733154297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Path to pre-trained model\n",
    "model_data_path = \"./NYU_ResNet-UpProj.npy\"\n",
    "# Default input size\n",
    "height = 228\n",
    "width = 304\n",
    "channels = 3\n",
    "batch_size = 1\n",
    "# Create a placeholder for the input image\n",
    "input_node = tf.placeholder(tf.float32, shape=(None, height, width, channels))\n",
    "    \n",
    "# Construct the network\n",
    "net = models.ResNet50UpProj({'data': input_node}, batch_size)\n",
    "    \n",
    "sess = tf.Session()\n",
    "    \n",
    "# Load the converted parameters\n",
    "start_time = time.time()\n",
    "print('Loading the model...')\n",
    "net.load(model_data_path, sess)\n",
    "    \n",
    "uninitialized_vars = []\n",
    "for var in tf.global_variables():\n",
    "    try:\n",
    "        sess.run(var)\n",
    "    except tf.errors.FailedPreconditionError:\n",
    "        uninitialized_vars.append(var)\n",
    "            \n",
    "init_new_vars_op = tf.variables_initializer(uninitialized_vars)\n",
    "sess.run(init_new_vars_op)\n",
    "print('Model is ready')\n",
    "print(\"--- Model loading time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the single depth images\n",
    "### You can skip this step to the next one if you want to predict series of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading image\n",
      "--- Image reading time : 0.01200103759765625 seconds ---\n",
      "Predicting\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Reading image')\n",
    "# Read image\n",
    "image_path = \"./Images/new_office.jpg\"\n",
    "img = Image.open(image_path)\n",
    "img = img.resize([width,height], Image.ANTIALIAS)\n",
    "img = np.array(img).astype('float32')\n",
    "img = np.expand_dims(np.asarray(img), axis = 0)\n",
    "print(\"--- Image reading time : %s seconds ---\" % (time.time() - start_time))\n",
    "print('Predicting')\n",
    "start_time = time.time()\n",
    "pred = sess.run(net.get_output(), feed_dict={input_node: img})\n",
    "print(type(pred))\n",
    "print(\"--- Predicting time : %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Plot result\n",
    "fig = plt.figure()\n",
    "ii = plt.imshow(pred[0,:,:,0], interpolation='nearest', cmap=plt.cm.get_cmap('Greys_r'))\n",
    "fig.colorbar(ii)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict multiple depth images\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test image saving\n",
    "im.imsave('name.jpg',pred[0,:,:,0],cmap=plt.cm.get_cmap('viridis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "1341847980.722988.png\n",
      "1341847980.722988.png saved in.\\output\n",
      "1341847980.754743.png\n",
      "1341847980.754743.png saved in.\\output\n",
      "1341847980.786856.png\n",
      "1341847980.786856.png saved in.\\output\n",
      "1341847980.822978.png\n",
      "1341847980.822978.png saved in.\\output\n",
      "1341847980.854676.png\n",
      "1341847980.854676.png saved in.\\output\n",
      "1341847980.890728.png\n",
      "1341847980.890728.png saved in.\\output\n",
      "1341847980.922978.png\n",
      "1341847980.922978.png saved in.\\output\n",
      "1341847980.954645.png\n",
      "1341847980.954645.png saved in.\\output\n",
      "1341847980.990699.png\n",
      "1341847980.990699.png saved in.\\output\n",
      "1341847981.022715.png\n",
      "1341847981.022715.png saved in.\\output\n",
      "1341847981.054711.png\n",
      "1341847981.054711.png saved in.\\output\n",
      "1341847981.090715.png\n",
      "1341847981.090715.png saved in.\\output\n",
      "1341847981.122985.png\n",
      "1341847981.122985.png saved in.\\output\n",
      "1341847981.158632.png\n",
      "1341847981.158632.png saved in.\\output\n",
      "1341847981.190636.png\n",
      "1341847981.190636.png saved in.\\output\n",
      "1341847981.222978.png\n",
      "1341847981.222978.png saved in.\\output\n",
      "1341847981.258722.png\n",
      "1341847981.258722.png saved in.\\output\n",
      "1341847981.290787.png\n",
      "1341847981.290787.png saved in.\\output\n",
      "--- Predicting time : 15.9610013961792 seconds ---\n"
     ]
    }
   ],
   "source": [
    "seriesPath = \".\\series\"\n",
    "outputPath = \".\\output\"\n",
    "seriesFiles = seriesPath + \"\\*.png\"\n",
    "# Length of path\n",
    "seriesPathLength = len(seriesPath)\n",
    "print(seriesPathLength)\n",
    "start_time = time.time()\n",
    "i = 0\n",
    "# get file name\n",
    "for file in glob.glob(seriesFiles):\n",
    "    filename = file[seriesPathLength + 1:]\n",
    "    print(filename)\n",
    "    img = Image.open(file)\n",
    "    img = img.resize([width,height], Image.ANTIALIAS)\n",
    "    img = np.array(img).astype('float32')\n",
    "    img = np.expand_dims(np.asarray(img), axis = 0)\n",
    "    # predict\n",
    "    pred = sess.run(net.get_output(), feed_dict={input_node: img})\n",
    "    # save the depth map\n",
    "    im.imsave(outputPath + \"\\\\\" + filename,pred[0,:,:,0],cmap=plt.cm.get_cmap('Greys'))\n",
    "    print (filename + \" saved\" + \" in\" + outputPath)\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "print(\"--- Predicting time : %s seconds ---\" % (time.time() - start_time))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
